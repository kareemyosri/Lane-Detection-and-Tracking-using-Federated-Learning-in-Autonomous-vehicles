{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827da507",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d913c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "import socket\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7455db1f",
   "metadata": {},
   "source": [
    "# Model Blocks and Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cf1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excite_block(inputs, ratio=8):\n",
    "    init = inputs\n",
    "    channel_axis = -1\n",
    "    filters = init.shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    x = Multiply()([init, se])\n",
    "    return x\n",
    "\n",
    "def stem_block(x, n_filter, strides):\n",
    "    x_init = x\n",
    "\n",
    "    ## Conv 1\n",
    "    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=strides)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(n_filter, (3, 3), padding=\"same\")(x)\n",
    "\n",
    "    ## Shortcut\n",
    "    s  = Conv2D(n_filter, (1, 1), padding=\"same\", strides=strides)(x_init)\n",
    "    s = BatchNormalization()(s)\n",
    "\n",
    "    ## Add\n",
    "    x = Add()([x, s])\n",
    "    x = squeeze_excite_block(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_block(x, n_filter, strides=1):\n",
    "    x_init = x\n",
    "\n",
    "    ## Conv 1\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=strides)(x)\n",
    "    ## Conv 2\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=1)(x)\n",
    "\n",
    "    ## Shortcut\n",
    "    s  = Conv2D(n_filter, (1, 1), padding=\"same\", strides=strides)(x_init)\n",
    "    s = BatchNormalization()(s)\n",
    "\n",
    "    ## Add\n",
    "    x = Add()([x, s])\n",
    "    x = squeeze_excite_block(x)\n",
    "    return x\n",
    "\n",
    "def aspp_block(x, num_filters, rate_scale=1):\n",
    "    x1 = Conv2D(num_filters, (3, 3), dilation_rate=(6 * rate_scale, 6 * rate_scale), padding=\"same\")(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "\n",
    "    x2 = Conv2D(num_filters, (3, 3), dilation_rate=(12 * rate_scale, 12 * rate_scale), padding=\"same\")(x)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "\n",
    "    x3 = Conv2D(num_filters, (3, 3), dilation_rate=(18 * rate_scale, 18 * rate_scale), padding=\"same\")(x)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "\n",
    "    x4 = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "\n",
    "    y = Add()([x1, x2, x3, x4])\n",
    "    y = Conv2D(num_filters, (1, 1), padding=\"same\")(y)\n",
    "    return y\n",
    "\n",
    "def attetion_block(g, x):\n",
    "    \"\"\"\n",
    "        g: Output of Parallel Encoder block\n",
    "        x: Output of Previous Decoder block\n",
    "    \"\"\"\n",
    "\n",
    "    filters = x.shape[-1]\n",
    "\n",
    "    g_conv = BatchNormalization()(g)\n",
    "    g_conv = Activation(\"relu\")(g_conv)\n",
    "    g_conv = Conv2D(filters, (3, 3), padding=\"same\")(g_conv)\n",
    "\n",
    "    g_pool = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(g_conv)\n",
    "\n",
    "    x_conv = BatchNormalization()(x)\n",
    "    x_conv = Activation(\"relu\")(x_conv)\n",
    "    x_conv = Conv2D(filters, (3, 3), padding=\"same\")(x_conv)\n",
    "\n",
    "    gc_sum = Add()([g_pool, x_conv])\n",
    "\n",
    "    gc_conv = BatchNormalization()(gc_sum)\n",
    "    gc_conv = Activation(\"relu\")(gc_conv)\n",
    "    gc_conv = Conv2D(filters, (3, 3), padding=\"same\")(gc_conv)\n",
    "\n",
    "    gc_mul = Multiply()([gc_conv, x])\n",
    "    return gc_mul\n",
    "\n",
    "def Resunetpp(sz = (256, 256, 3)):\n",
    "    x = Input(sz)\n",
    "    n_filters = [16, 32, 64, 128, 256]\n",
    "    c0 = x\n",
    "    c1 = stem_block(c0, n_filters[0], strides=1)\n",
    "\n",
    "    ## Encoder\n",
    "    c2 = resnet_block(c1, n_filters[1], strides=2)\n",
    "    c3 = resnet_block(c2, n_filters[2], strides=2)\n",
    "    c4 = resnet_block(c3, n_filters[3], strides=2)\n",
    "\n",
    "    ## Bridge\n",
    "    b1 = aspp_block(c4, n_filters[4])\n",
    "\n",
    "    ## Decoder\n",
    "    d1 = attetion_block(c3, b1)\n",
    "    d1 = UpSampling2D((2, 2))(d1)\n",
    "    d1 = Concatenate()([d1, c3])\n",
    "    d1 = resnet_block(d1, n_filters[3])\n",
    "\n",
    "    d2 = attetion_block(c2, d1)\n",
    "    d2 = UpSampling2D((2, 2))(d2)\n",
    "    d2 = Concatenate()([d2, c2])\n",
    "    d2 = resnet_block(d2, n_filters[2])\n",
    "\n",
    "    d3 = attetion_block(c1, d2)\n",
    "    d3 = UpSampling2D((2, 2))(d3)\n",
    "    d3 = Concatenate()([d3, c1])\n",
    "    d3 = resnet_block(d3, n_filters[1])\n",
    "\n",
    "    ## output\n",
    "    outputs = aspp_block(d3, n_filters[0])\n",
    "    outputs = Conv2D(1, (1, 1), padding=\"same\")(outputs)\n",
    "    outputs = Activation(\"sigmoid\")(outputs)\n",
    "\n",
    "    ## Model\n",
    "    model = Model(x, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae32be",
   "metadata": {},
   "source": [
    "# Federated Preperation Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc598dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    #logits = model.predict(X_test, batch_size=100)\n",
    "    logits = model.predict(X_test)\n",
    "    loss = dice_coef_loss(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2102184",
   "metadata": {},
   "source": [
    "# Federated average with all clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e35d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_local_weight_list=[]\n",
    "for file_name in os.listdir('E:/NU/Federated/send_recieve'):\n",
    "    local_model = Resunetpp() \n",
    "    #set local model weight to the weight of the global model\n",
    "    local_model.load_weights('E:/NU/Federated/send_recieve/'+file_name)    #scale the model weights and add to list\n",
    "    \n",
    "    scaled_local_weight_list.append(local_model.get_weights())\n",
    "        \n",
    "    #clear session to free memory after each communication round\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb0958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = Resunetpp()\n",
    "\n",
    "#to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "#update global model \n",
    "global_model.set_weights(average_weights)\n",
    "\n",
    "#save global model weights\n",
    "global_model.save_weights(r\"E:\\NU\\Federated\\send_recieve/updated.h5\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9a888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ead0eed14181618a8c4058dc68539503edf8fba89331e9ab1f1ea187ca61c7e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
